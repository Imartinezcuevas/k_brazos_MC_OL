{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Principal: Problema del Bandido de los k-Brazos\n",
    "\n",
    "Notebook principal del proyecto. Desde aquí, puedes acceder y navegar entre los distintos notebooks de experimentos relacionados con el problema del bandido de los k-brazos.\n",
    "\n",
    "    Author: Iván Martínez Cuevas y Antonio Orenes Lucas\n",
    "    Email: ivan.martinezc@um.es y antonio.orenesl@um.es\n",
    "    Date: 2025/02/12\n",
    "\n",
    "This software is licensed under the GNU General Public License v3.0 (GPL-3.0),\n",
    "with the additional restriction that it may not be used for commercial purposes.\n",
    "\n",
    "For more details about GPL-3.0: https://www.gnu.org/licenses/gpl-3.0.html\n",
    "\n",
    "## Instrucciones\n",
    "1. **Ejecuta las primeras celdas** para clonar el repositorio e instalar los paquetes necesarios.\n",
    "2. **Explora los experimentos** accediendo a los notebooks individuales desde los enlaces proporcionados más adelante.\n",
    "\n",
    "A continuación, se presenta una introducción al problema y una descripción de los experimentos que realizaremos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema del bandido de k-brazos\n",
    "\n",
    "## ¿Sobre qué trata el problema del bandido de k-brazos?\n",
    "Es un problema clásico de aprendizaje por refuerzo donde un agente debe tomar decisiones en un entorno incierto para maximizar su recompensa a lo largo del tiempo.\n",
    "\n",
    "### Analogía con una máquina tragamonedas\n",
    "En un casino hay **k** máquinas tragamonedas diferentes (**brazos**). Cada una tiene una **distribución** de recompensa desconocida:\n",
    "* Algunas máquinas dan dinero frequentemente.\n",
    "* Otras dan menos a menudo, pero cuando lo dan el premio suele ser más grande.\n",
    "\n",
    "El objetivo es encontrar la máquina que da la mayor ganancia en el largo plazo, pero sin saber cúal es al inicio.\n",
    "\n",
    "Para lograrlo, debemos decidir entre:\n",
    "* **Exploración**: probamos máquinas diferentes para descrubir cual es mejor.\n",
    "* **Explotación**: utilizamos la máquina que creemos que da la mejor recompensa basado en lo que ya sabemos.\n",
    "\n",
    "Este dilema entre **exploración y explotación** es el **corazón del problema**.\n",
    "\n",
    "## ¿Cómo se modela matemáticamente?\n",
    "El problema se define con los siguientes elementos:\n",
    "* $k$: Número de brazos disponible.\n",
    "* $a_t$: Acción elegida en el instante t (qué brazo seleccionamos).\n",
    "* $r_t$: Recompensa obtenida en el tiempo $t$ tras elegir $a_t$.\n",
    "\n",
    "Cada brazo tiene una distribución de recompensa desconocida $P(r_t| a_t = a)$, y el objetivo es maximizar la recompensa total:\n",
    "$$max\\sum_{t=1}^{T} r_t$$\n",
    "Donde $T$ es el horizonte temporal.\n",
    "\n",
    "## ¿Cómo resolvemos este problema? (Distintos experimentos)\n",
    "Existen varios algoritmos que intentan equilibar la exploración con la explotacion. En este trabajo vamos a probar y comparar algunos de ellos.\n",
    "1. Epsilon-greedy\n",
    "2. Upper Confidence Bound (UCB)\n",
    "3. Ascenso del gradiente: Softmax y Gradiente de Preferencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enlaces a estudios (notebooks)\n",
    "\n",
    "A continuación se adjuntan los enlaces a los distintos estudios realizados:\n",
    "\n",
    "[Epsilon-Greedy](https://colab.research.google.com/github/Imartinezcuevas/k_brazos_MC_OL/blob/main/bandit_experiment_epsilon_greedy.ipynb)\n",
    "\n",
    "[UCB](https://colab.research.google.com/github/Imartinezcuevas/k_brazos_MC_OL/blob/main/bandit_experiment_ucb.ipynb)\n",
    "\n",
    "[Ascenso de Gradiente](https://colab.research.google.com/github/Imartinezcuevas/k_brazos_MC_OL/blob/main/bandit_experiment_gradient_ascent.ipynb)\n",
    "\n",
    "[Epsilon-Greedy VS Ascenso de Gradiente](https://colab.research.google.com/github/Imartinezcuevas/k_brazos_MC_OL/blob/main/bandit_experiment_GreedyVsGPreferencias.ipynb)\n",
    "\n",
    "[UCB2 VS Ascenso de Gradiente](https://colab.research.google.com/github/Imartinezcuevas/k_brazos_MC_OL/blob/main/bandit_experiment_UCB2vsGPreferencias.ipynb)\n",
    "\n",
    "[Comparación final](https://colab.research.google.com/github/Imartinezcuevas/k_brazos_MC_OL/blob/main/bandit_experiment_ComparacionFinal.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
